{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from random import *\n",
    "import timeit\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6\n",
    "n = 6\n",
    "gen  = n*m\n",
    "edges = []\n",
    "operators = n\n",
    "#1) Input network file\n",
    "links = 2*m*n-m-n; # number of links\n",
    "link = dict()\n",
    "for i in range(1,n*m+1):\n",
    "        if (i % n != 0):\n",
    "            if ( gen - i >= n):\n",
    "                edges.extend([(i,i+1),(i+1,i),(i,i+m),(i+m,i)])\n",
    "            else: \n",
    "                edges.extend([(i,i+1),(i+1,i)])\n",
    "        else: \n",
    "            if ( gen - i >= n):\n",
    "                edges.extend([(i,i+m),(i+m,i)])\n",
    "            else: \n",
    "                break;  \n",
    "tt = dict();\n",
    "capacity = dict();\n",
    "operator = dict();\n",
    "failure_prob = dict();\n",
    "edge_dict = dict()\n",
    "fail = [];\n",
    "prob = [];\n",
    "lst_prob = [];\n",
    "K = [];\n",
    "demand = dict();\n",
    "cost = dict();\n",
    "count = 0;\n",
    "G = nx.DiGraph()\n",
    "for edge in edges: \n",
    "    edge_dict[edge] = count;\n",
    "    count +=1;\n",
    "    capacity[edge] = int(randrange(gen)/5+1)\n",
    "    operator[edge] = randrange(operators)\n",
    "    tt[edge] = randrange(100)\n",
    "    G.add_edge(edge[0],edge[1], weight = tt[edge])\n",
    "    cost[edge] = tt[edge]\n",
    "    z = random()\n",
    "    if z <= 0.8 and len(fail) < n + 4:\n",
    "        p = int(random()*10/10.0) + 0.6;\n",
    "        failure_prob[edge] = min(p,1);\n",
    "        prob.append(p);\n",
    "        fail.append(edge)\n",
    "        K.append(edge)\n",
    "        demand[edge] = randrange(gen)*100\n",
    "        lst_prob.append(p)\n",
    "    else:\n",
    "        failure_prob[edge] = 0;\n",
    "        lst_prob.append(0)\n",
    "\n",
    "oper_list = list(range(operators))\n",
    "# Each O-D pair will have an alternative dummy path 10 x times than the shortest path \n",
    "import networkx as nx\n",
    "used_cap = dict()\n",
    "path_cost = dict()\n",
    "for pair in K:\n",
    "    unavailable = []\n",
    "    try:\n",
    "            path = nx.shortest_path(G, source=pair[0], target=pair[1], weight = 'weight')\n",
    "            for edge in list(zip(path,path[1:])):\n",
    "                if pair[0]==edge[0]:\n",
    "                    path_cost[(pair[0],pair[1])] = cost[edge]\n",
    "                else:\n",
    "                    path_cost[(pair[0],pair[1])] = + cost[edge]\n",
    "           # print(path)\n",
    "    except nx.NetworkXNoPath as error:\n",
    "        print(error.args)\n",
    "        #raise Exception(\"not exists\")\n",
    "        #print(\"not exist\")    \n",
    "nd = gen+1\n",
    "dummy = []\n",
    "for x,y in list(enumerate(path_cost)):\n",
    "    lst_prob.append(0);\n",
    "    lst_prob.append(0);\n",
    "    edges.append((y[0], nd));\n",
    "    edges.append((nd ,y[1]));\n",
    "    dummy.append((y[0], nd))\n",
    "    dummy.append((nd ,y[1]));\n",
    "    tt[(y[0],nd)] = 5 * path_cost[y];\n",
    "    tt[(nd,y[1])] = 5 * path_cost[y];\n",
    "    failure_prob[(y[0],nd )] = 0;\n",
    "    failure_prob[(nd ,y[1])] = 0;\n",
    "    nd += 1;\n",
    "nodes = list(range(1,nd))\n",
    "inflow = {node: [] for node in nodes}\n",
    "outflow = deepcopy(inflow)\n",
    "for edge in edges:\n",
    "    inflow[edge[1]] += [edge]\n",
    "    outflow[edge[0]] += [edge]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation time of L-Shaped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-99999999.0\n",
      "-99999999.0\n",
      "-99999999.0\n",
      "-99999999.0\n",
      "-99999999.0\n",
      "-99999999.0\n",
      "3348638.799999999\n",
      "Number of scenarios : 256\n",
      "L-Shaped time is : 44.57984258400393\n",
      "3348638.799999999\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Calculating scenario tree\n",
    "occurencies = list(itertools.product([0, 1], repeat=len(prob)));\n",
    "outcome =[];\n",
    "for lst in occurencies: \n",
    "    temp = 1;\n",
    "    z = -1;\n",
    "    for elem in lst:\n",
    "        z += 1;\n",
    "        if elem == 0:\n",
    "            temp = temp * (1 - prob[z]);\n",
    "        else: \n",
    "            temp = temp * prob[z];\n",
    "    outcome.append(temp)  \n",
    "#outcome = [ round(elem, 3) for elem in outcome ]\n",
    "failed = { m : k for k,m in enumerate(list(fail))}\n",
    "P = len(outcome)\n",
    "J = 1 #2*len(oper_list)*P; # x-only inequalities\n",
    "M = len(oper_list)#+len(oper_list)*P; # x vars\n",
    "dataA = np.zeros((M))\n",
    "rowA = np.zeros(M)\n",
    "colA = np.arange((M))\n",
    "A = sp.csr_matrix((dataA, (rowA, colA)), shape=(J,M))\n",
    "b = np.zeros((1,J));\n",
    "big_M = 99999999;\n",
    "A_dict = dict();\n",
    "k = 0;\n",
    "for i in oper_list:\n",
    "    A_dict[i] = k;\n",
    "    k += 1;\n",
    "# construct dictionaries\n",
    "p = np.array(outcome);\n",
    "y_k_dict = dict();\n",
    "tmp_q = [];\n",
    "k = 0;\n",
    "for pair in K:\n",
    "    for edge in edges:\n",
    "        tmp_q.append(tt[edge]);\n",
    "        y_k_dict[edge,pair] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[2,edge] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[3,edge] = k;\n",
    "        k += 1;\n",
    "# sizing \n",
    "L = len(y_k_dict); #y variables\n",
    "R = 2*len(nodes)*len(K) # flow constr\n",
    "R += len(edges) # capacity constr\n",
    "R += 1 # total excess \n",
    "R += len(oper_list) # allocated excess \n",
    "R += 2*len(oper_list) # total_slack\n",
    "#R += 2*len(edges) #e,s<=M*b\n",
    "# number of scenarios\n",
    "# construct c matrix\n",
    "c = np.zeros((M,1));\n",
    "# construct q matrix\n",
    "q = np.zeros((L,P));\n",
    "for i in range(L):\n",
    "    for j in range(P):\n",
    "        q[i,j] = tmp_q[i];\n",
    "# construct T matrix \n",
    "#T = [ [ [ 0 for i in range(P) ] for j in range(M)] for z in range(R)];\n",
    "T = np.zeros((R,M,P));\n",
    "# construct h matrix \n",
    "h =  np.zeros((R,P));\n",
    "# Second level constraints\n",
    "k = 0;\n",
    "dataW = np.empty(0)\n",
    "rowW = np.empty(0)\n",
    "colW = np.empty(0)\n",
    "# flow constraints \n",
    "for pair in K:\n",
    "    temp = demand[pair];\n",
    "    for node in nodes:\n",
    "        if node == pair[0]:\n",
    "            rhs = temp;\n",
    "        elif node == pair[1]:\n",
    "            rhs = -temp;\n",
    "        else:\n",
    "            rhs = 0;\n",
    "        for s in range(P):\n",
    "            h[k,s] = rhs;\n",
    "            h[k+1,s] = -rhs;\n",
    "        for edge in outflow[node]: \n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        for edge in inflow[node]:      \n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        k += 2;\n",
    "# capacity constraints\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        dataW = np.append(dataW,-1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[3,edge])\n",
    "        for pair in K:\n",
    "            dataW = np.append(dataW,1)\n",
    "            rowW = np.append(rowW,k)\n",
    "            colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        for s in range(P):\n",
    "            if failure_prob[edge]>0 and occurencies[s][failed[edge]]==1:\n",
    "                  h[k,s] = 0;\n",
    "            else:\n",
    "                  h[k,s] = capacity[edge];\n",
    "        k += 1;\n",
    "# Allocated excess \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper:\n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[2,edge])\n",
    "        for oper2 in oper_list: \n",
    "            if oper2 != oper:\n",
    "                for s in range(P):\n",
    "                    T[k,A_dict[oper2],s] = -1;             \n",
    "        k += 1\n",
    "# Total excess\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "for s in range(P):\n",
    "    for oper2 in oper_list: \n",
    "            T[k,A_dict[oper2],s] = -1;  \n",
    "k += 1;\n",
    "# Total deficit \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper: \n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "                    dataW = np.append(dataW,-1)\n",
    "                    rowW = np.append(rowW,k+1)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "        for s in range(P):\n",
    "             T[k,A_dict[oper],s] = -1;  \n",
    "             T[k+1,A_dict[oper],s] = 1;  \n",
    "        k += 2;\n",
    "W = sp.csr_matrix((dataW, (rowW, colW)), shape=(R,L))\n",
    "stop0 = timeit.default_timer()\n",
    "\n",
    "####### L-shaped method #######\n",
    "\n",
    "m = Model('master')\n",
    "m.setParam('OutputFlag', 0)\n",
    "A_2 = deepcopy(A)\n",
    "A_2._shape = (np.shape(A_2)[0], np.shape(A_2)[1]+1)\n",
    "x = m.addMVar(shape=np.shape(A_2)[1],lb=np.append(np.zeros((1,np.shape(A_2)[1]-1)),-big_M), vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "c_null = np.append(c,0)\n",
    "c_augmented = np.append(c,1)\n",
    "m.setObjective(c_null @ x , GRB.MINIMIZE)\n",
    "m.addConstr(A_2 @ x <= b, name=\"c\")\n",
    "m.setParam(\"NodeMethod\", 2);\n",
    "m.setParam(\"Presolve\", 0);\n",
    "m.update()\n",
    "m.Params.OutputFlag = 0\n",
    "num_y_constraints = np.shape(W)[0] \n",
    "num_y_values = np.shape(W)[1] \n",
    "#K = np.shape(p)[0]\n",
    "# Preparing feasiblity sub-problem sparse matrix\n",
    "dataf = deepcopy(dataW)\n",
    "rowf = deepcopy(rowW)\n",
    "colf = deepcopy(colW)\n",
    "for i in range(num_y_constraints):\n",
    "    dataf = np.append(dataf,1)\n",
    "    rowf = np.append(rowf,i)\n",
    "    colf = np.append(colf,2 * i  + num_y_values)\n",
    "    dataf = np.append(dataf,-1)\n",
    "    rowf = np.append(rowf,i)\n",
    "    colf = np.append(colf,2 * i+1+ num_y_values)\n",
    "constraint_k = sp.csr_matrix((dataf, (rowf, colf)), shape=(num_y_constraints, num_y_values + 2 * num_y_constraints))\n",
    "num_feasibility_cuts = 0;\n",
    "num_optimality_cuts = 0;\n",
    "num_iterations = 0;\n",
    "review = []\n",
    "while True: \n",
    "    num_iterations += 1;\n",
    "    \n",
    "    # Solve the master problem    \n",
    "    if num_optimality_cuts == 0:\n",
    "        m.setObjective(c_null @ x , GRB.MINIMIZE)\n",
    "        m.update()\n",
    "        m.optimize()\n",
    "        if m.Status!=2:\n",
    "            break;\n",
    "    else:\n",
    "        m.setObjective(c_augmented @ x , GRB.MINIMIZE)\n",
    "        m.update()\n",
    "        m.optimize()\n",
    "        if m.Status!=2:\n",
    "            break;\n",
    "    review.append(m.ObjVal)\n",
    "    x_augmented =  [var.x for var in  m.getVars()];\n",
    "    x_optimal =  np.array(x_augmented[:len(x_augmented)-1])\n",
    "    if num_optimality_cuts == 0:\n",
    "        theta = -big_M;\n",
    "    else:\n",
    "        theta = x_augmented[len(x_augmented)-1]\n",
    "        \n",
    "    # Check if there is a need for feasibility cuts\n",
    "    init_r = num_feasibility_cuts;\n",
    "    for k in range(P):\n",
    "        m1 = Model('feasibility cut')\n",
    "        m1.Params.OutputFlag = 0;\n",
    "        m1.setParam(\"NodeMethod\", 2);\n",
    "        m1.setParam(\"Presolve\", 0);\n",
    "        v = m1.addMVar(shape=num_y_values+2*num_y_constraints,lb=0, vtype=GRB.CONTINUOUS, name=\"v\");\n",
    "        f = np.append(np.zeros(num_y_values),np.ones(2*num_y_constraints));\n",
    "        m1.setObjective(f @ v , GRB.MINIMIZE);\n",
    "        m1.addConstr(constraint_k @ v <= h[:,k]-np.dot(T[:,:,k],np.transpose(x_optimal)), name=\"c1\")\n",
    "        m1.optimize()\n",
    "        if m1.Status != 2:\n",
    "            break;\n",
    "        if m1.ObjVal >0.001:\n",
    "            # Feasibility cut\n",
    "            dual = np.array(m1.getAttr(\"Pi\", m1.getConstrs()));\n",
    "            coef = np.append(np.dot(dual,T[:,:,k]),0);\n",
    "            bound = np.dot(dual,h[:,k]);\n",
    "            coef = np.array([round(elem,3) for elem in coef]);\n",
    "            bound = round(bound,3);\n",
    "            m.addConstr(coef @ x >= bound);\n",
    "            m.update();\n",
    "            num_feasibility_cuts += 1;\n",
    "            break;\n",
    "    if init_r == num_feasibility_cuts:\n",
    "        bound_sum = 0;\n",
    "        constraint_sum = np.zeros((1,np.shape(c)[0]));\n",
    "        for k in range(P):\n",
    "            m2 = Model('optimality cut');\n",
    "            m2.setParam('OutputFlag', 0);\n",
    "            m2.setParam(\"NodeMethod\", 2);\n",
    "            m2.setParam(\"Presolve\", 0);\n",
    "            y = m2.addMVar(shape=num_y_values,lb=0, vtype=GRB.CONTINUOUS, name=\"y\");\n",
    "            m2.setObjective(q[:,k] @ y , GRB.MINIMIZE);\n",
    "            m2.addConstr(W @ y <= h[:,k]-np.dot(T[:,:,k],np.transpose(x_optimal)), name=\"c2\")\n",
    "            m2.update()\n",
    "            m2.Params.OutputFlag = 0\n",
    "            m2.optimize()\n",
    "            dual = np.array(m2.getAttr(\"Pi\", m2.getConstrs()));\n",
    "            bound_sum += p[k] * np.dot(dual,h[:,k]);  \n",
    "            constraint_sum += p[k] * np.dot(dual,T[:,:,k]);\n",
    "        current_sum = -np.dot(constraint_sum,np.transpose(x_optimal)) + bound_sum; \n",
    "        print(m.ObjVal)\n",
    "        # Stopping criterion\n",
    "        int_stop = timeit.default_timer()\n",
    "        if   current_sum.item() <= theta or abs(theta-current_sum.item())/abs(current_sum.item())<=0.1:\n",
    "            break;\n",
    "        else:\n",
    "            # Optimality cut\n",
    "            constraint_sum = np.append(constraint_sum, 1) ;\n",
    "            m.addConstr(constraint_sum @ x >= bound_sum)\n",
    "            num_optimality_cuts += 1;\n",
    "stop1 = timeit.default_timer()\n",
    "\n",
    "print(\"Number of scenarios :\", P)\n",
    "print(\"L-Shaped time is :\", stop1-start)\n",
    "print(m.objVal)\n",
    "#print(\"opt gap of L-Shaped is {} %\".format(round(100 * abs(m3.objVal - m.objVal)/m3.objVal,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational time of DEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.0 build v9.0.0rc2 (mac64)\n",
      "Optimize a model with 118017 rows, 163844 columns and 702464 nonzeros\n",
      "Model fingerprint: 0x52bd9f35\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e-04, 7e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 77825 rows and 34176 columns\n",
      "Presolve time: 0.66s\n",
      "Presolved: 40192 rows, 129668 columns, 370560 nonzeros\n",
      "\n",
      "Ordering time: 0.03s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 4\n",
      " AA' NZ     : 2.681e+05\n",
      " Factor NZ  : 1.239e+06 (roughly 80 MBytes of memory)\n",
      " Factor Ops : 4.639e+07 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   4.46661743e+07  0.00000000e+00  9.68e+04 0.00e+00  1.61e+03     1s\n",
      "   1   1.28022526e+07  8.00036890e+05  2.19e+04 8.21e-01  4.18e+02     1s\n",
      "   2   5.07802636e+06  1.95403125e+06  5.68e+03 3.72e-01  1.30e+02     1s\n",
      "   3   3.13890154e+06  2.63392426e+06  2.17e+03 1.25e-01  4.45e+01     1s\n",
      "   4   2.90253117e+06  2.87868085e+06  1.55e+03 7.00e-02  2.96e+01     1s\n",
      "   5   2.89522123e+06  3.01247705e+06  1.37e+03 5.48e-02  2.59e+01     2s\n",
      "   6   2.93249621e+06  3.08022651e+06  1.19e+03 4.10e-02  2.19e+01     2s\n",
      "   7   2.99961786e+06  3.12626293e+06  9.37e+02 3.55e-02  1.78e+01     2s\n",
      "   8   3.03050183e+06  3.17855460e+06  7.49e+02 2.57e-02  1.42e+01     2s\n",
      "   9   3.07810646e+06  3.23816712e+06  4.80e+02 7.11e-03  8.30e+00     2s\n",
      "  10   3.10573287e+06  3.29045919e+06  3.32e+02 2.72e-03  5.55e+00     2s\n",
      "  11   3.13122226e+06  3.30635706e+06  2.96e+02 2.22e-03  5.05e+00     2s\n",
      "  12   3.16326973e+06  3.31493529e+06  2.58e+02 1.97e-03  4.49e+00     2s\n",
      "  13   3.18273230e+06  3.32973761e+06  2.19e+02 1.64e-03  3.79e+00     2s\n",
      "  14   3.19182497e+06  3.33702904e+06  2.04e+02 1.36e-03  3.49e+00     2s\n",
      "  15   3.25131481e+06  3.33620971e+06  1.30e+02 1.11e-03  2.29e+00     3s\n",
      "  16   3.35564803e+06  3.34360759e+06  5.29e-01 7.16e-05  1.05e-01     3s\n",
      "  17   3.35034942e+06  3.34468389e+06  5.20e-02 4.28e-05  4.64e-02     3s\n",
      "\n",
      "Barrier performed 17 iterations in 2.82 seconds\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 22355 iterations and 2.85 seconds\n",
      "Optimal objective  3.348638800e+06\n",
      "Number of scenarios : 256\n",
      "DEP time is : 7.078146234998712\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "# Calculating scenario tree\n",
    "occurencies = list(itertools.product([0, 1], repeat=len(prob)));\n",
    "outcome =[];\n",
    "for lst in occurencies: \n",
    "    temp = 1;\n",
    "    z = -1;\n",
    "    for elem in lst:\n",
    "        z += 1;\n",
    "        if elem == 0:\n",
    "            temp = temp * (1 - prob[z]);\n",
    "        else: \n",
    "            temp = temp * prob[z];\n",
    "    outcome.append(temp)  \n",
    "#outcome = [ round(elem, 3) for elem in outcome ]\n",
    "failed = { m : k for k,m in enumerate(list(fail))}\n",
    "P = len(outcome)\n",
    "J = 1 #2*len(oper_list)*P; # x-only inequalities\n",
    "M = len(oper_list)#+len(oper_list)*P; # x vars\n",
    "dataA = np.zeros((M))\n",
    "rowA = np.zeros(M)\n",
    "colA = np.arange((M))\n",
    "A = sp.csr_matrix((dataA, (rowA, colA)), shape=(J,M))\n",
    "b = np.zeros((1,J));\n",
    "big_M = 9999999999;\n",
    "A_dict = dict();\n",
    "k = 0;\n",
    "for i in oper_list:\n",
    "    A_dict[i] = k;\n",
    "    k += 1;\n",
    "# construct dictionaries\n",
    "p = np.array(outcome);\n",
    "y_k_dict = dict();\n",
    "tmp_q = [];\n",
    "k = 0;\n",
    "for pair in K:\n",
    "    for edge in edges:\n",
    "        tmp_q.append(tt[edge]);\n",
    "        y_k_dict[edge,pair] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[2,edge] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[3,edge] = k;\n",
    "        k += 1;\n",
    "# sizing \n",
    "L = len(y_k_dict); #y variables\n",
    "R = 2*len(nodes)*len(K) # flow constr\n",
    "R += len(edges) # capacity constr\n",
    "R += 1 # total excess \n",
    "R += len(oper_list) # allocated excess \n",
    "R += 2*len(oper_list) # total_slack\n",
    "#R += 2*len(edges) #e,s<=M*b\n",
    "# number of scenarios\n",
    "# construct c matrix\n",
    "c = np.zeros((M,1));\n",
    "# construct q matrix\n",
    "q = np.zeros((L,P));\n",
    "for i in range(L):\n",
    "    for j in range(P):\n",
    "        q[i,j] = tmp_q[i];\n",
    "# construct T matrix \n",
    "#T = [ [ [ 0 for i in range(P) ] for j in range(M)] for z in range(R)];\n",
    "T = np.zeros((R,M,P));\n",
    "# construct h matrix \n",
    "h =  np.zeros((R,P));\n",
    "# Second level constraints\n",
    "k = 0;\n",
    "dataW = np.empty(0)\n",
    "rowW = np.empty(0)\n",
    "colW = np.empty(0)\n",
    "# flow constraints \n",
    "for pair in K:\n",
    "    temp = demand[pair];\n",
    "    for node in nodes:\n",
    "        if node == pair[0]:\n",
    "            rhs = temp;\n",
    "        elif node == pair[1]:\n",
    "            rhs = -temp;\n",
    "        else:\n",
    "            rhs = 0;\n",
    "        for s in range(P):\n",
    "            h[k,s] = rhs;\n",
    "            h[k+1,s] = -rhs;\n",
    "        for edge in outflow[node]: \n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        for edge in inflow[node]:      \n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        k += 2;\n",
    "# capacity constraints\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        dataW = np.append(dataW,-1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[3,edge])\n",
    "        for pair in K:\n",
    "            dataW = np.append(dataW,1)\n",
    "            rowW = np.append(rowW,k)\n",
    "            colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        for s in range(P):\n",
    "            if failure_prob[edge]>0 and occurencies[s][failed[edge]]==1:\n",
    "                  h[k,s] = 0;\n",
    "            else:\n",
    "                  h[k,s] = capacity[edge];\n",
    "        k += 1;\n",
    "# Allocated excess \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper:\n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[2,edge])\n",
    "        for oper2 in oper_list: \n",
    "            if oper2 != oper:\n",
    "                for s in range(P):\n",
    "                    T[k,A_dict[oper2],s] = -1;             \n",
    "        k += 1\n",
    "# Total excess\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "for s in range(P):\n",
    "    for oper2 in oper_list: \n",
    "            T[k,A_dict[oper2],s] = -1;  \n",
    "k += 1;\n",
    "# Total deficit \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper: \n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "                    dataW = np.append(dataW,-1)\n",
    "                    rowW = np.append(rowW,k+1)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "        for s in range(P):\n",
    "             T[k,A_dict[oper],s] = -1;  \n",
    "             T[k+1,A_dict[oper],s] = 1;  \n",
    "        k += 2;\n",
    "W = sp.csr_matrix((dataW, (rowW, colW)), shape=(R,L))\n",
    "stop0 = timeit.default_timer()\n",
    "\n",
    "####### DEP #######\n",
    "\n",
    "b_2 = deepcopy(b);\n",
    "c_2 = deepcopy(c)\n",
    "data_2 = deepcopy(dataA)\n",
    "row_2 = deepcopy(rowA)\n",
    "col_2 = deepcopy(colA)\n",
    "J = np.shape(A)[0]\n",
    "M = np.shape(A)[1]\n",
    "R = np.shape(W)[0]\n",
    "L = np.shape(W)[1]\n",
    "for k in range(P):\n",
    "    c_2 = np.append(c_2,p[k] * q[:,k])\n",
    "    b_2 = np.append(b_2,h[:,k])\n",
    "    data_2 = np.append(data_2,dataW) \n",
    "    row_2 = np.append(row_2,rowW + J + k * R)\n",
    "    col_2 = np.append(col_2,colW + M + k * L)\n",
    "    T_k = sp.csr_matrix(T[:,:,k])\n",
    "    rowT, colT = T_k.nonzero()\n",
    "    dataT = T_k[rowT,colT]\n",
    "    data_2 = np.append(data_2,dataT) \n",
    "    row_2 = np.append(row_2,rowT + J + k * R)\n",
    "    col_2 = np.append(col_2,colT)\n",
    "A_2 = sp.csr_matrix((data_2, (row_2, col_2)), shape = (J + P * R,M + P * L));\n",
    "m3 = Model('DEP');\n",
    "x = m3.addMVar(shape = np.shape(c_2)[0],lb = 0, vtype=GRB.CONTINUOUS, name = \"x\");\n",
    "m3.setObjective(c_2 @ x , GRB.MINIMIZE);\n",
    "m3.addConstr(A_2 @ x <= b_2);\n",
    "m3.update();\n",
    "m3.optimize();\n",
    "stop2 = timeit.default_timer()\n",
    "print(\"Number of scenarios :\", P);\n",
    "#print(\"L-Shaped time is :\", stop1-start)\n",
    "print(\"DEP time is :\" , stop2-start);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational time of SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.0 build v9.0.0rc2 (mac64)\n",
      "Optimize a model with 46101 rows, 64004 columns and 274400 nonzeros\n",
      "Model fingerprint: 0x68ed4a8f\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e-02, 4e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 30489 rows and 13498 columns\n",
      "Presolve time: 0.26s\n",
      "Presolved: 15612 rows, 50506 columns, 145098 nonzeros\n",
      "\n",
      "Ordering time: 0.02s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 4\n",
      " AA' NZ     : 1.043e+05\n",
      " Factor NZ  : 4.826e+05 (roughly 30 MBytes of memory)\n",
      " Factor Ops : 1.793e+07 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   4.46495768e+07  0.00000000e+00  9.02e+04 0.00e+00  2.36e+03     0s\n",
      "   1   1.09715617e+07  4.33750100e+05  1.98e+04 9.68e-01  5.69e+02     0s\n",
      "   2   3.68351629e+06  1.59733569e+06  4.96e+03 4.11e-01  1.65e+02     1s\n",
      "   3   1.77534776e+06  2.35818115e+06  1.35e+03 1.19e-01  3.47e+01     1s\n",
      "   4   2.22577108e+06  3.02907300e+06  6.10e+02 7.84e-02  1.57e+01     1s\n",
      "   5   2.62484836e+06  3.13572812e+06  3.61e+02 3.04e-02  8.19e+00     1s\n",
      "   6   2.82025791e+06  3.21800154e+06  2.28e+02 1.29e-02  4.64e+00     1s\n",
      "   7   2.91599861e+06  3.30746457e+06  1.65e+02 9.26e-03  3.00e+00     1s\n",
      "   8   3.19607393e+06  3.26053016e+06  7.40e+01 7.13e-03  3.25e+00     1s\n",
      "   9   3.22089672e+06  3.26596934e+06  5.80e+01 6.67e-03  2.79e+00     1s\n",
      "  10   3.23488548e+06  3.30762579e+06  5.18e+01 3.87e-03  1.91e+00     1s\n",
      "  11   3.30707606e+06  3.34175500e+06  1.90e+01 6.20e-04  5.38e-01     1s\n",
      "\n",
      "Barrier performed 11 iterations in 0.90 seconds\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 9355 iterations and 0.91 seconds\n",
      "Optimal objective  3.348748150e+06\n",
      "Network with pairs : 8\n",
      "SAA samples : 100\n",
      "Network with nodes : 16\n",
      "SAA time is : 1.9963938530127052\n",
      "opt gap of SAA is 0.0033 %\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "J = 1 #2*len(oper_list)*P; # x-only inequalities\n",
    "M = len(oper_list)#+len(oper_list)*P; # x vars\n",
    "dataA = np.zeros((M))\n",
    "rowA = np.zeros(M)\n",
    "colA = np.arange((M))\n",
    "A = sp.csr_matrix((dataA, (rowA, colA)), shape=(J,M))\n",
    "b = np.zeros((1,J));\n",
    "big_M = 9999999999;\n",
    "A_dict = dict();\n",
    "k = 0;\n",
    "for i in oper_list:\n",
    "    A_dict[i] = k;\n",
    "    k += 1;\n",
    "# construct dictionaries\n",
    "y_k_dict = dict();\n",
    "tmp_q = [];\n",
    "k = 0;\n",
    "for pair in K:\n",
    "    for edge in edges:\n",
    "        tmp_q.append(tt[edge]);\n",
    "        y_k_dict[edge,pair] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[2,edge] = k;\n",
    "        k += 1;\n",
    "for edge in edges:\n",
    "        tmp_q.append(0);\n",
    "        y_k_dict[3,edge] = k;\n",
    "        k += 1;\n",
    "# sizing \n",
    "L = len(y_k_dict); #y variables\n",
    "R = 2*len(nodes)*len(K) # flow constr\n",
    "R += len(edges) # capacity constr\n",
    "R += 1 # total excess \n",
    "R += len(oper_list) # allocated excess \n",
    "R += 2*len(oper_list) # total_slack\n",
    "#R += 2*len(edges) #e,s<=M*b\n",
    "# number of scenarios\n",
    "# construct c matrix\n",
    "c = np.zeros((M,1));\n",
    "# construct q matrix\n",
    "#q = np.zeros((L,P));\n",
    "#for i in range(L):\n",
    " #   for j in range(P):\n",
    "  #      q[i,j] = tmp_q[i];\n",
    "# construct T matrix \n",
    "#T = [ [ [ 0 for i in range(P) ] for j in range(M)] for z in range(R)];\n",
    "T = np.zeros((R,M));\n",
    "# construct h matrix \n",
    "h =  np.zeros((R));\n",
    "# Second level constraints\n",
    "k = 0;\n",
    "dataW = np.empty(0)\n",
    "rowW = np.empty(0)\n",
    "colW = np.empty(0)\n",
    "# flow constraints \n",
    "for pair in K:\n",
    "    temp = demand[pair];\n",
    "    for node in nodes:\n",
    "        if node == pair[0]:\n",
    "            rhs = temp;\n",
    "        elif node == pair[1]:\n",
    "            rhs = -temp;\n",
    "        else:\n",
    "            rhs = 0;\n",
    "        h[k] = rhs;\n",
    "        h[k+1] = -rhs;\n",
    "        for edge in outflow[node]: \n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        for edge in inflow[node]:      \n",
    "                dataW = np.append(dataW,-1)\n",
    "                rowW = np.append(rowW,k)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "                dataW = np.append(dataW,1)\n",
    "                rowW = np.append(rowW,k+1)\n",
    "                colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        k += 2;\n",
    "# capacity constraints\n",
    "constr_rows = []\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        constr_rows.append(k)\n",
    "        dataW = np.append(dataW,-1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[3,edge])\n",
    "        h[k] = capacity[edge];\n",
    "        for pair in K:\n",
    "            dataW = np.append(dataW,1)\n",
    "            rowW = np.append(rowW,k)\n",
    "            colW = np.append(colW,y_k_dict[edge,pair])\n",
    "        k += 1;\n",
    "    #for s in range(P):\n",
    "        #if failure_prob[edge]>0 and occurencies[s][failed[edge]]==1:\n",
    "             # h[k,s] = 0;\n",
    "        #else:\n",
    "              #h[k,s] = capacity[edge];\n",
    "            \n",
    "# Allocated excess \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper:\n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[2,edge])\n",
    "        for oper2 in oper_list: \n",
    "            if oper2 != oper:\n",
    "                T[k,A_dict[oper2]] = -1;             \n",
    "        k += 1\n",
    "# Total excess\n",
    "for edge in edges:\n",
    "    if edge not in dummy:\n",
    "        dataW = np.append(dataW,1)\n",
    "        rowW = np.append(rowW,k)\n",
    "        colW = np.append(colW,y_k_dict[2,edge])\n",
    "for oper2 in oper_list: \n",
    "        T[k,A_dict[oper2]] = -1;  \n",
    "k += 1;\n",
    "# Total deficit \n",
    "for oper in oper_list:\n",
    "        for edge in edges:\n",
    "            if edge not in dummy:\n",
    "                if operator[edge] == oper: \n",
    "                    dataW = np.append(dataW,1)\n",
    "                    rowW = np.append(rowW,k)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "                    dataW = np.append(dataW,-1)\n",
    "                    rowW = np.append(rowW,k+1)\n",
    "                    colW = np.append(colW,y_k_dict[3,edge])\n",
    "        #for s in range(P):\n",
    "        T[k,A_dict[oper]] = -1;  \n",
    "        T[k+1,A_dict[oper]] = 1;  \n",
    "        k += 2;\n",
    "W = sp.csr_matrix((dataW, (rowW, colW)), shape=(R,L))\n",
    "J = np.shape(A)[0]\n",
    "M = np.shape(A)[1]\n",
    "R = np.shape(W)[0]\n",
    "L = np.shape(W)[1]\n",
    "q = np.array(tmp_q)\n",
    "b_2 = deepcopy(b);\n",
    "c_2 = deepcopy(c);\n",
    "data_2 = deepcopy(dataA)\n",
    "row_2 = deepcopy(rowA)\n",
    "col_2 = deepcopy(colA)\n",
    "lst_prob = np.array(deepcopy(lst_prob))\n",
    "count = -1\n",
    "p_sample = np.zeros((len(lst_prob),))\n",
    "rtol = 5e-02\n",
    "atol = 1e-02\n",
    "cap_begin = constr_rows[0]\n",
    "while count<=98: #(np.allclose(p_sample, lst_prob,rtol,atol) == False):\n",
    "    count +=1\n",
    "    h_trial = deepcopy(h)\n",
    "    # bernouli trial\n",
    "    occur = np.random.binomial(1, p=lst_prob)\n",
    "    for elem in np.nonzero(occur)[0]:\n",
    "          h_trial[elem+cap_begin] = 0;\n",
    "    p_sample = (occur+(count)*p_sample)/(count+1)\n",
    "    c_2 = np.append(c_2,1.0*q)\n",
    "    b_2 = np.append(b_2,h_trial)\n",
    "    data_2 = np.append(data_2,dataW) \n",
    "    row_2 = np.append(row_2,rowW + J + count * R)\n",
    "    col_2 = np.append(col_2,colW + M + count * L)\n",
    "    T_k = sp.csr_matrix(T)\n",
    "    rowT, colT = T_k.nonzero()\n",
    "    dataT = T_k[rowT,colT]\n",
    "    data_2 = np.append(data_2,dataT) \n",
    "    row_2 = np.append(row_2,rowT + J + count * R)\n",
    "    col_2 = np.append(col_2,colT)\n",
    "A_3 = sp.csr_matrix((data_2, (row_2, col_2)), shape=(J + (count+1)*R, M + (count+1)*L))\n",
    "m4 = Model('Monte');\n",
    "c_2 = c_2.astype(float)\n",
    "c_2[M:] = c_2[M:] / (count+1)\n",
    "x = m4.addMVar(shape = np.shape(c_2)[0],lb=0, vtype=GRB.CONTINUOUS, name=\"x\");\n",
    "m4.update()\n",
    "m4.setObjective(c_2 @ x , GRB.MINIMIZE);\n",
    "m4.addConstr(A_3 @ x <= b_2)\n",
    "m4.update()\n",
    "m4.optimize()\n",
    "stop3 = timeit.default_timer()\n",
    "print(\"Network with pairs :\", len(K))\n",
    "print(\"SAA samples :\", count+1)\n",
    "print(\"Network with nodes :\", gen)\n",
    "print(\"SAA time is :\", stop3 - start)\n",
    "print(\"opt gap of SAA is {} %\".format(round(100*abs(m.objVal - m4.objVal)/m.objVal,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parameters \n",
    "import pickle\n",
    "scenarios = 2**len(prob)\n",
    "pickle.dump( tt, open( \"cost_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( demand, open( \"demand_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( lst_prob, open( \"failures_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( operator, open( \"operators_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( capacity, open( \"capacity_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( prob, open( \"only_failed_{}.p\".format(scenarios), \"wb\" ) )\n",
    "pickle.dump( K, open( \"OD_pair_{}.p\".format(scenarios), \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
